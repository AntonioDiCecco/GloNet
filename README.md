
# GloNets: Globally Connected Neural Networks

<p float="left">
  <img src="https://github.com/AntonioDiCecco/GloNet/blob/main/Images/GloNet-fc.jpg" width="50%" />
  <img src="[Images/](https://github.com/AntonioDiCecco/GloNet/blob/main/)Glonet-tunable.png" width="50%" /> 
</p>


## Abstract
GloNets introduces a novel neural network architecture that surpasses depth-related limitations of existing deep learning structures. Differing from architectures like ResNet, GloNets ensure stable training and uniform information distribution across all network layers. This allows for superimposing GloNets on any model to enhance depth without increasing complexity or reducing performance.

## Repository Contents
`\Code\PyTorch`: Implementation of GloNet in various configurations:
- `GloNet+fc`: GloNet applied to fully connected networks.
- `GloNet+CNN`: GloNet integration with Convolutional Neural Networks.
- `GloNet+ViT`: GloNet combined with Vision Transformers.

`\Images`: Contains images demonstrating GloNet's architecture and its post-learning tunable precision.

## Usage
Details on using the code in different scenarios will be provided here.

```
## Citation
If you use this work in your research, please cite:
Di Cecco, A., Metta, C., Fantozzi, M., Morandin, F., Parton, M. (2023). GloNets: Globally Connected Neural Networks. arXiv preprint arXiv:2311.15947.
[Link to the preprint](https://arxiv.org/abs/2311.15947)

Presented at the [IDA 2024 Conference](https://ida2024.blogs.dsv.su.se).
```

## License
Information about the license used for the code and repository contents.

## Contact
Details for further information or collaboration opportunities.

## Acknowledgments
Acknowledgments to those who, with their work, inspired this project, e.g. Yoshua Bengio and Simone Scardapane.
